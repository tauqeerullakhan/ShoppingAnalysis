{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Lang_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abkhazian</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afar</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albanian</td>\n",
       "      <td>sq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amharic</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Wolof</td>\n",
       "      <td>wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Xhosa</td>\n",
       "      <td>xh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>yi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Yoruba</td>\n",
       "      <td>yo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Zulu</td>\n",
       "      <td>zu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Language Lang_Code\n",
       "0    Abkhazian        ab\n",
       "1         Afar        aa\n",
       "2    Afrikaans        af\n",
       "3     Albanian        sq\n",
       "4      Amharic        am\n",
       "..         ...       ...\n",
       "136      Wolof        wo\n",
       "137      Xhosa        xh\n",
       "138    Yiddish        yi\n",
       "139     Yoruba        yo\n",
       "140       Zulu        zu\n",
       "\n",
       "[140 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Get the Language description\n",
    "df_lang = pd.read_html('https://docs.oracle.com/cd/E13214_01/wli/docs92/xref/xqisocodes.html', match='ISO-639 Language Codes')[0]\n",
    "df_lang.rename(columns ={'ISO-639 Language Code': 'Lang_Code'}, inplace = True)\n",
    "\n",
    "# Delete the duplicate Lang code 'zh' for Chinese\n",
    "index_zh = df_lang[ df_lang['Language'] == 'Chinese (Traditional)' ].index\n",
    "df_lang.drop(index_zh , inplace=True)\n",
    "df_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US_state_codes = pd.read_html('https://developer.cybersource.com/library/documentation/dev_guides/SmallBusiness/Intershop_NT/html/appC.html')[1]\n",
    "df_US_state_codes.rename(columns ={'Two-Character Code': 'State_Code'}, inplace = True)\n",
    "\n",
    "# Handle duplicate State Code 'AE'\n",
    "index_AE = df_US_state_codes[ (df_US_state_codes['State'] == 'Armed Forces Africa') | (df_US_state_codes['State'] == 'Armed Forces Canada')|(df_US_state_codes['State'] == 'Armed Forces Europe')].index\n",
    "df_US_state_codes.drop(index_AE , inplace=True)\n",
    "df_US_state_codes.iloc[df_US_state_codes[df_US_state_codes['State_Code'] == 'AE'].index-3, 0] = 'Armed Forces - Africa/ME/Canada/Europe'\n",
    "# df_US_state_codes[df_US_state_codes.State_Code == 'ME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lang_Code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0c0c90514dd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Add Language description using MERGE statement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf_ecom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Language'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Lang_Code'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf_ecom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ecom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_lang\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Lang_Code'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdf_ecom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Address2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ecom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Address'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Lang_Code'"
     ]
    }
   ],
   "source": [
    "# Data cleansing and enhancement\n",
    "df_ecom = pd.read_csv('https://github.com/tauqeerullakhan/ShoppingAnalysis/blob/main/Ecommerce_Purchases.csv')\n",
    "df_ecom_bkp = df_ecom\n",
    "\n",
    "df_ecom.drop_duplicates()\n",
    "# df_ecom.isna().sum()\n",
    "\n",
    "# Add Language description using MERGE statement\n",
    "df_ecom.rename(columns ={'Language': 'Lang_Code'}, inplace = True)\n",
    "df_ecom = pd.merge(df_ecom,df_lang,how = 'left', on = 'Lang_Code' )\n",
    "df_ecom['Address2'] = df_ecom['Address']\n",
    "\n",
    "# Populate the State code \n",
    "df_ecom['State_Code'] = (df_ecom.Address.str.split(',', expand = True)[1]).str.split(' ', expand = True)[[1]]\n",
    "\n",
    "df_none = (df_ecom.Address.str.split(',', expand = True)[1]).str.split(' ', expand = True)[[0]]\n",
    "# df_none\n",
    "\n",
    "idx_none = (df_none[df_none[0]!='']).index\n",
    "# idx_none\n",
    "\n",
    "for i in idx_none:\n",
    "    df_ecom.iloc[i,16] = df_ecom.iloc[i,0].split(' ')[-2]\n",
    "\n",
    "# Enhance the CC provider details\n",
    "df_ecom['CC Provider_Lvl2'] = df_ecom['CC Provider']   \n",
    "df_ecom['CC Provider'].replace(to_replace=['VISA 16 digit', 'JCB 16 digit', 'JCB 15 digit', 'VISA 13 digit'], value=['VISA', 'JCB', 'JCB', 'VISA'], inplace=True)\n",
    "    \n",
    "# Remove the redundant columns - 'Credit Card', 'IP Address', 'CC Security Code', 'CC Exp Date'\n",
    "df_ecom.drop(columns = [ 'Credit Card', 'IP Address', 'CC Security Code', 'CC Exp Date', 'Address2'], inplace = True)\n",
    "df_ecom = pd.merge(df_ecom,df_US_state_codes,how = 'left', on = 'State_Code' )\n",
    "df_ecom['Currency']='$'\n",
    "\n",
    "df_ecom['Users'] = (df_ecom.Email.str.split('@', expand = True)[0]).str.split(' ', expand = True)[[0]]\n",
    "df_ecom['UserCount'] = 1\n",
    "\n",
    "\n",
    "df_ecom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecom_top_users = pd.pivot_table(data=df_ecom,   \n",
    "                                   values = ['Purchase Price'], index=['Email', 'Users'],\n",
    "                                   aggfunc = 'sum',).nlargest(5, ['Purchase Price'], keep='first')\n",
    "# df_ecom_top_users.index.get_level_values(1)\n",
    "df_ecom_top_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_Top5Users = px.bar(data_frame = df_ecom_top_users, y= df_ecom_top_users.index.get_level_values(1), x='Purchase Price', \n",
    "                       labels={'y':'Users', 'Purchase Price': 'Purchase Price - $'},orientation = 'h' , width=800, height=400,\n",
    "                      title = 'Premium Customers based on Purchase')\n",
    "fig_Top5Users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lang_distr2 = px.pie(data_frame = df_ecom, names = 'Language', values = 'UserCount', \n",
    "                         hole=.3, width=500, height=400,\n",
    "                        title = 'User groups based on Language')\n",
    "\n",
    "fig_lang_distr2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_tim_distr = px.pie(data_frame = df_ecom, names = 'AM or PM', values = 'UserCount',hole=.3,\n",
    "                      title = 'Buying pattern during AM/PM', width=400, height=400)\n",
    "fig_tim_distr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_am_pm = pd.pivot_table(data=df_ecom, index=['AM or PM'], values = 'Purchase Price', \n",
    "                                   aggfunc = 'sum')\n",
    "\n",
    "fig_tim_distr2 = px.bar(data_frame = pivot_am_pm, y = pivot_am_pm.index, x = 'Purchase Price',\n",
    "                      title = 'Total purchase on the day - split per AM/PM',  \n",
    "                        width=700, height=400, text = 'Purchase Price', \n",
    "                        labels={'Purchase Price': 'Purchase Price - $'})\n",
    "fig_tim_distr2.update_traces(texttemplate='%{text:.2s}', textposition='inside')\n",
    "fig_tim_distr2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_comp_pur_prc= pd.pivot_table(data=df_ecom, index=['Company'], values = 'Purchase Price', \n",
    "                                   aggfunc = 'sum').nlargest(10, 'Purchase Price', keep='first')\n",
    "pivot_comp_pur_usrcnt = pd.pivot_table(data=df_ecom, index=['Company'], values = 'UserCount', \n",
    "                                       aggfunc = 'sum').nlargest(10, 'UserCount', keep='first')\n",
    "\n",
    "a4_dims = (16.7, 5.27)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=a4_dims)\n",
    "pivot_comp_pur_prc.plot(ax = ax1, kind = 'bar' , title='Top 10 Companies based on Puchase Price')\n",
    "pivot_comp_pur_usrcnt.plot(ax = ax2, kind = 'bar', title='Top 10 Companies based on Employee Purchase')\n",
    "\n",
    "\n",
    "# fig_comp_pur_prc= sns.barplot(ax = ax, data=pivot_comp_pur_prc, x=pivot_comp_pur_prc.index, y='Purchase Price',orient = 'v')\n",
    "# fig_comp_pur_prc= sns.barplot(ax = ax, data=pivot_comp_pur_prc, y=pivot_comp_pur_prc.index, x='Purchase Price',orient = 'h')\n",
    "# fig_comp_pur_prc.set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_state_pur_top= pd.pivot_table(data=df_ecom, index=['State'], values = 'Purchase Price', aggfunc = 'sum').nlargest(5, 'Purchase Price', keep='first')\n",
    "pivot_state_usrcnt = pd.pivot_table(data=df_ecom, index=['State'], values = 'UserCount', aggfunc = 'sum').nlargest(5, 'UserCount', keep='first')\n",
    "\n",
    "pivot_state_pur_bottom= pd.pivot_table(data=df_ecom, index=['State'], values = 'Purchase Price', aggfunc = 'sum').nsmallest(5, 'Purchase Price', keep='first')\n",
    "\n",
    "a4_dims = (16.7, 10.27)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=a4_dims)\n",
    "fig_state_prc_top= sns.barplot(ax = ax1, data=pivot_state_pur_top, y=pivot_state_pur_top.index, \n",
    "                               x='Purchase Price',orient = 'h').set_title('Top 5 purchases based on Area')\n",
    "fig_state_prc_bottom = sns.barplot(ax = ax2, data=pivot_state_pur_bottom, y=pivot_state_pur_bottom.index, \n",
    "                                   x='Purchase Price',orient = 'h'). set_title('Bottom 5 purchases based on Area')\n",
    "# fig_state_usrcnt= sns.barplot(ax = ax, data=pivot_state_usrcnt, y=pivot_state_usrcnt.index, x='UserCount',orient = 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_CC_provider = px.pie(data_frame = df_ecom, names = 'CC Provider', values = 'UserCount' , \n",
    "                         width=700, height=500,\n",
    "                        title = 'Usage share per Credit Card provider')\n",
    "fig_CC_provider.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_CC_provider_prc = px.pie(data_frame = df_ecom, names = 'CC Provider', values = 'Purchase Price')\n",
    "fig_CC_provider_prc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_job_pur= pd.pivot_table(data=df_ecom, index=['Job'], values = 'Purchase Price', aggfunc = 'sum').nlargest(5, 'Purchase Price', keep='first')\n",
    "\n",
    "# a4_dims = (11.7, 8.27)\n",
    "# fig, ax = plt.subplots(figsize=a4_dims)\n",
    "# fig_job_prc= sns.barplot(ax = ax, data=pivot_job_pur, y=pivot_job_pur.index, x='Purchase Price',orient = 'h')\n",
    "\n",
    "fig_job_prc = px.bar(data_frame=pivot_job_pur, x='Purchase Price', y=pivot_job_pur.index, \n",
    "                     color='Purchase Price' , \n",
    "                     width=1000, height=300,\n",
    "                    labels={'Job':'Occupation', 'Purchase Price': 'Purchase Price - $'}, \n",
    "                    title = 'Top 5 customer groups based on occupation')\n",
    "fig_job_prc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state = pd.pivot_table(df_ecom, values = ['Purchase Price', 'UserCount'], \n",
    "                          index = ['State_Code', 'State'], aggfunc = 'sum')\n",
    "\n",
    "fig = px.scatter_geo(df_state, locations= df_state.index.get_level_values(0), locationmode = 'USA-states', scope = 'usa', \n",
    "                      hover_data = {'State': df_state.index.get_level_values(1), 'Purchase Price': ':.2f', 'UserCount':':d'},\n",
    "                    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state = pd.pivot_table(df_ecom, values = ['Purchase Price', 'UserCount'], index = ['State_Code', 'State'], aggfunc = 'sum')\n",
    "df_state.index.get_level_values(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
